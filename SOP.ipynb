{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HxGZuwIS9MxkTrw14uVzZ3ZPiEvraU1Z",
      "authorship_tag": "ABX9TyMdvE1ziEzC9NEPL8fODVjC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harikrishnan-developer/SOPGENERATOR/blob/main/SOP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langchain-community langchain-core pypdf sentence-transformers chromadb markdown llama-cpp-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhhSolMGi_cf",
        "outputId": "23f05e01-535b-43e5-b6c7-624fcaf88c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.63)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (3.8)\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.9.tar.gz (67.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.44)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-4.4.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.34.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.34.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.72.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.55b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.55b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.55b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.6.0-py3-none-any.whl (304 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.55b0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.55b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.34.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-4.4.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: llama-cpp-python, pypika\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.9-cp311-cp311-linux_x86_64.whl size=4067760 sha256=2fa348e79243a3d37fb9ac1f338aab02086349ce44eb474ea6b5f6383639a4a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/8f/bf/148c8eb7d69021eccd6eae6444f3accd48347587054ffd24e5\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=6c9138e60f39275fbcf79e1f7aa4ef83442ff354bef7ab39bb707bd324345e35\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built llama-cpp-python pypika\n",
            "Installing collected packages: pypika, durationpy, watchdog, uvloop, python-dotenv, pypdf, overrides, opentelemetry-util-http, opentelemetry-proto, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, diskcache, bcrypt, backoff, asgiref, watchfiles, typing-inspect, starlette, pydeck, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, llama-cpp-python, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, nvidia-cusolver-cu12, kubernetes, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation, streamlit, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, langchain-community, chromadb\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.46.2\n",
            "    Uninstalling starlette-0.46.2:\n",
            "      Successfully uninstalled starlette-0.46.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.115.12\n",
            "    Uninstalling fastapi-0.115.12:\n",
            "      Successfully uninstalled fastapi-0.115.12\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.12 coloredlogs-15.0.1 dataclasses-json-0.6.7 diskcache-5.6.3 durationpy-0.10 fastapi-0.115.9 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-32.0.1 langchain-community-0.3.24 llama-cpp-python-0.3.9 marshmallow-3.26.1 mmh3-5.1.0 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.0 opentelemetry-api-1.34.0 opentelemetry-exporter-otlp-proto-common-1.34.0 opentelemetry-exporter-otlp-proto-grpc-1.34.0 opentelemetry-instrumentation-0.55b0 opentelemetry-instrumentation-asgi-0.55b0 opentelemetry-instrumentation-fastapi-0.55b0 opentelemetry-proto-1.34.0 opentelemetry-sdk-1.34.0 opentelemetry-semantic-conventions-0.55b0 opentelemetry-util-http-0.55b0 overrides-7.7.0 posthog-4.4.0 pydantic-settings-2.9.1 pydeck-0.9.1 pypdf-5.6.0 pypika-0.48.9 python-dotenv-1.1.0 starlette-0.45.3 streamlit-1.45.1 typing-inspect-0.9.0 uvloop-0.21.0 watchdog-6.0.0 watchfiles-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-huggingface\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kZ9HixHg7Py",
        "outputId": "70b915db-3f46-4231-cd70-1f9cc7a42794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.63)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.52.4)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.3.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (2.11.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import llama_cpp\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/agentic_sop_project/models/meta-llama-3-8b.Q4_K_M.gguf\"\n",
        "llm = llama_cpp.Llama(model_path=model_path, n_ctx=2048, n_gpu_layers=20)\n",
        "\n",
        "prompt = \"Write a short introduction for a finance SOP.\"\n",
        "output = llm(prompt, max_tokens=128)\n",
        "print(output[\"choices\"][0][\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnC2-5JPSfBx",
        "outputId": "fc964079-6c17-41bc-a742-68cc612ce82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /content/drive/MyDrive/agentic_sop_project/models/meta-llama-3-8b.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 4.58 GiB (4.89 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 128255 '<|reserved_special_token_250|>' is not marked as EOG\n",
            "load: control token: 128254 '<|reserved_special_token_249|>' is not marked as EOG\n",
            "load: control token: 128253 '<|reserved_special_token_248|>' is not marked as EOG\n",
            "load: control token: 128251 '<|reserved_special_token_246|>' is not marked as EOG\n",
            "load: control token: 128246 '<|reserved_special_token_241|>' is not marked as EOG\n",
            "load: control token: 128243 '<|reserved_special_token_238|>' is not marked as EOG\n",
            "load: control token: 128240 '<|reserved_special_token_235|>' is not marked as EOG\n",
            "load: control token: 128239 '<|reserved_special_token_234|>' is not marked as EOG\n",
            "load: control token: 128238 '<|reserved_special_token_233|>' is not marked as EOG\n",
            "load: control token: 128237 '<|reserved_special_token_232|>' is not marked as EOG\n",
            "load: control token: 128232 '<|reserved_special_token_227|>' is not marked as EOG\n",
            "load: control token: 128228 '<|reserved_special_token_223|>' is not marked as EOG\n",
            "load: control token: 128227 '<|reserved_special_token_222|>' is not marked as EOG\n",
            "load: control token: 128225 '<|reserved_special_token_220|>' is not marked as EOG\n",
            "load: control token: 128222 '<|reserved_special_token_217|>' is not marked as EOG\n",
            "load: control token: 128215 '<|reserved_special_token_210|>' is not marked as EOG\n",
            "load: control token: 128211 '<|reserved_special_token_206|>' is not marked as EOG\n",
            "load: control token: 128210 '<|reserved_special_token_205|>' is not marked as EOG\n",
            "load: control token: 128204 '<|reserved_special_token_199|>' is not marked as EOG\n",
            "load: control token: 128203 '<|reserved_special_token_198|>' is not marked as EOG\n",
            "load: control token: 128201 '<|reserved_special_token_196|>' is not marked as EOG\n",
            "load: control token: 128197 '<|reserved_special_token_192|>' is not marked as EOG\n",
            "load: control token: 128196 '<|reserved_special_token_191|>' is not marked as EOG\n",
            "load: control token: 128195 '<|reserved_special_token_190|>' is not marked as EOG\n",
            "load: control token: 128193 '<|reserved_special_token_188|>' is not marked as EOG\n",
            "load: control token: 128191 '<|reserved_special_token_186|>' is not marked as EOG\n",
            "load: control token: 128190 '<|reserved_special_token_185|>' is not marked as EOG\n",
            "load: control token: 128185 '<|reserved_special_token_180|>' is not marked as EOG\n",
            "load: control token: 128184 '<|reserved_special_token_179|>' is not marked as EOG\n",
            "load: control token: 128182 '<|reserved_special_token_177|>' is not marked as EOG\n",
            "load: control token: 128181 '<|reserved_special_token_176|>' is not marked as EOG\n",
            "load: control token: 128177 '<|reserved_special_token_172|>' is not marked as EOG\n",
            "load: control token: 128176 '<|reserved_special_token_171|>' is not marked as EOG\n",
            "load: control token: 128175 '<|reserved_special_token_170|>' is not marked as EOG\n",
            "load: control token: 128174 '<|reserved_special_token_169|>' is not marked as EOG\n",
            "load: control token: 128173 '<|reserved_special_token_168|>' is not marked as EOG\n",
            "load: control token: 128172 '<|reserved_special_token_167|>' is not marked as EOG\n",
            "load: control token: 128168 '<|reserved_special_token_163|>' is not marked as EOG\n",
            "load: control token: 128167 '<|reserved_special_token_162|>' is not marked as EOG\n",
            "load: control token: 128166 '<|reserved_special_token_161|>' is not marked as EOG\n",
            "load: control token: 128165 '<|reserved_special_token_160|>' is not marked as EOG\n",
            "load: control token: 128162 '<|reserved_special_token_157|>' is not marked as EOG\n",
            "load: control token: 128159 '<|reserved_special_token_154|>' is not marked as EOG\n",
            "load: control token: 128155 '<|reserved_special_token_150|>' is not marked as EOG\n",
            "load: control token: 128153 '<|reserved_special_token_148|>' is not marked as EOG\n",
            "load: control token: 128152 '<|reserved_special_token_147|>' is not marked as EOG\n",
            "load: control token: 128151 '<|reserved_special_token_146|>' is not marked as EOG\n",
            "load: control token: 128148 '<|reserved_special_token_143|>' is not marked as EOG\n",
            "load: control token: 128146 '<|reserved_special_token_141|>' is not marked as EOG\n",
            "load: control token: 128144 '<|reserved_special_token_139|>' is not marked as EOG\n",
            "load: control token: 128143 '<|reserved_special_token_138|>' is not marked as EOG\n",
            "load: control token: 128141 '<|reserved_special_token_136|>' is not marked as EOG\n",
            "load: control token: 128139 '<|reserved_special_token_134|>' is not marked as EOG\n",
            "load: control token: 128138 '<|reserved_special_token_133|>' is not marked as EOG\n",
            "load: control token: 128135 '<|reserved_special_token_130|>' is not marked as EOG\n",
            "load: control token: 128133 '<|reserved_special_token_128|>' is not marked as EOG\n",
            "load: control token: 128132 '<|reserved_special_token_127|>' is not marked as EOG\n",
            "load: control token: 128131 '<|reserved_special_token_126|>' is not marked as EOG\n",
            "load: control token: 128130 '<|reserved_special_token_125|>' is not marked as EOG\n",
            "load: control token: 128128 '<|reserved_special_token_123|>' is not marked as EOG\n",
            "load: control token: 128125 '<|reserved_special_token_120|>' is not marked as EOG\n",
            "load: control token: 128121 '<|reserved_special_token_116|>' is not marked as EOG\n",
            "load: control token: 128120 '<|reserved_special_token_115|>' is not marked as EOG\n",
            "load: control token: 128119 '<|reserved_special_token_114|>' is not marked as EOG\n",
            "load: control token: 128116 '<|reserved_special_token_111|>' is not marked as EOG\n",
            "load: control token: 128112 '<|reserved_special_token_107|>' is not marked as EOG\n",
            "load: control token: 128109 '<|reserved_special_token_104|>' is not marked as EOG\n",
            "load: control token: 128107 '<|reserved_special_token_102|>' is not marked as EOG\n",
            "load: control token: 128106 '<|reserved_special_token_101|>' is not marked as EOG\n",
            "load: control token: 128105 '<|reserved_special_token_100|>' is not marked as EOG\n",
            "load: control token: 128103 '<|reserved_special_token_98|>' is not marked as EOG\n",
            "load: control token: 128100 '<|reserved_special_token_95|>' is not marked as EOG\n",
            "load: control token: 128099 '<|reserved_special_token_94|>' is not marked as EOG\n",
            "load: control token: 128098 '<|reserved_special_token_93|>' is not marked as EOG\n",
            "load: control token: 128094 '<|reserved_special_token_89|>' is not marked as EOG\n",
            "load: control token: 128088 '<|reserved_special_token_83|>' is not marked as EOG\n",
            "load: control token: 128087 '<|reserved_special_token_82|>' is not marked as EOG\n",
            "load: control token: 128086 '<|reserved_special_token_81|>' is not marked as EOG\n",
            "load: control token: 128084 '<|reserved_special_token_79|>' is not marked as EOG\n",
            "load: control token: 128082 '<|reserved_special_token_77|>' is not marked as EOG\n",
            "load: control token: 128078 '<|reserved_special_token_73|>' is not marked as EOG\n",
            "load: control token: 128075 '<|reserved_special_token_70|>' is not marked as EOG\n",
            "load: control token: 128073 '<|reserved_special_token_68|>' is not marked as EOG\n",
            "load: control token: 128072 '<|reserved_special_token_67|>' is not marked as EOG\n",
            "load: control token: 128070 '<|reserved_special_token_65|>' is not marked as EOG\n",
            "load: control token: 128065 '<|reserved_special_token_60|>' is not marked as EOG\n",
            "load: control token: 128064 '<|reserved_special_token_59|>' is not marked as EOG\n",
            "load: control token: 128062 '<|reserved_special_token_57|>' is not marked as EOG\n",
            "load: control token: 128060 '<|reserved_special_token_55|>' is not marked as EOG\n",
            "load: control token: 128059 '<|reserved_special_token_54|>' is not marked as EOG\n",
            "load: control token: 128057 '<|reserved_special_token_52|>' is not marked as EOG\n",
            "load: control token: 128056 '<|reserved_special_token_51|>' is not marked as EOG\n",
            "load: control token: 128054 '<|reserved_special_token_49|>' is not marked as EOG\n",
            "load: control token: 128051 '<|reserved_special_token_46|>' is not marked as EOG\n",
            "load: control token: 128043 '<|reserved_special_token_38|>' is not marked as EOG\n",
            "load: control token: 128042 '<|reserved_special_token_37|>' is not marked as EOG\n",
            "load: control token: 128041 '<|reserved_special_token_36|>' is not marked as EOG\n",
            "load: control token: 128040 '<|reserved_special_token_35|>' is not marked as EOG\n",
            "load: control token: 128035 '<|reserved_special_token_30|>' is not marked as EOG\n",
            "load: control token: 128033 '<|reserved_special_token_28|>' is not marked as EOG\n",
            "load: control token: 128032 '<|reserved_special_token_27|>' is not marked as EOG\n",
            "load: control token: 128029 '<|reserved_special_token_24|>' is not marked as EOG\n",
            "load: control token: 128025 '<|reserved_special_token_20|>' is not marked as EOG\n",
            "load: control token: 128024 '<|reserved_special_token_19|>' is not marked as EOG\n",
            "load: control token: 128021 '<|reserved_special_token_16|>' is not marked as EOG\n",
            "load: control token: 128020 '<|reserved_special_token_15|>' is not marked as EOG\n",
            "load: control token: 128019 '<|reserved_special_token_14|>' is not marked as EOG\n",
            "load: control token: 128018 '<|reserved_special_token_13|>' is not marked as EOG\n",
            "load: control token: 128015 '<|reserved_special_token_10|>' is not marked as EOG\n",
            "load: control token: 128013 '<|reserved_special_token_8|>' is not marked as EOG\n",
            "load: control token: 128012 '<|reserved_special_token_7|>' is not marked as EOG\n",
            "load: control token: 128010 '<|reserved_special_token_5|>' is not marked as EOG\n",
            "load: control token: 128005 '<|reserved_special_token_3|>' is not marked as EOG\n",
            "load: control token: 128004 '<|reserved_special_token_2|>' is not marked as EOG\n",
            "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
            "load: control token: 128249 '<|reserved_special_token_244|>' is not marked as EOG\n",
            "load: control token: 128187 '<|reserved_special_token_182|>' is not marked as EOG\n",
            "load: control token: 128180 '<|reserved_special_token_175|>' is not marked as EOG\n",
            "load: control token: 128134 '<|reserved_special_token_129|>' is not marked as EOG\n",
            "load: control token: 128179 '<|reserved_special_token_174|>' is not marked as EOG\n",
            "load: control token: 128037 '<|reserved_special_token_32|>' is not marked as EOG\n",
            "load: control token: 128045 '<|reserved_special_token_40|>' is not marked as EOG\n",
            "load: control token: 128089 '<|reserved_special_token_84|>' is not marked as EOG\n",
            "load: control token: 128212 '<|reserved_special_token_207|>' is not marked as EOG\n",
            "load: control token: 128104 '<|reserved_special_token_99|>' is not marked as EOG\n",
            "load: control token: 128205 '<|reserved_special_token_200|>' is not marked as EOG\n",
            "load: control token: 128142 '<|reserved_special_token_137|>' is not marked as EOG\n",
            "load: control token: 128028 '<|reserved_special_token_23|>' is not marked as EOG\n",
            "load: control token: 128126 '<|reserved_special_token_121|>' is not marked as EOG\n",
            "load: control token: 128198 '<|reserved_special_token_193|>' is not marked as EOG\n",
            "load: control token: 128071 '<|reserved_special_token_66|>' is not marked as EOG\n",
            "load: control token: 128092 '<|reserved_special_token_87|>' is not marked as EOG\n",
            "load: control token: 128183 '<|reserved_special_token_178|>' is not marked as EOG\n",
            "load: control token: 128140 '<|reserved_special_token_135|>' is not marked as EOG\n",
            "load: control token: 128226 '<|reserved_special_token_221|>' is not marked as EOG\n",
            "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
            "load: control token: 128052 '<|reserved_special_token_47|>' is not marked as EOG\n",
            "load: control token: 128053 '<|reserved_special_token_48|>' is not marked as EOG\n",
            "load: control token: 128058 '<|reserved_special_token_53|>' is not marked as EOG\n",
            "load: control token: 128150 '<|reserved_special_token_145|>' is not marked as EOG\n",
            "load: control token: 128149 '<|reserved_special_token_144|>' is not marked as EOG\n",
            "load: control token: 128209 '<|reserved_special_token_204|>' is not marked as EOG\n",
            "load: control token: 128169 '<|reserved_special_token_164|>' is not marked as EOG\n",
            "load: control token: 128157 '<|reserved_special_token_152|>' is not marked as EOG\n",
            "load: control token: 128038 '<|reserved_special_token_33|>' is not marked as EOG\n",
            "load: control token: 128178 '<|reserved_special_token_173|>' is not marked as EOG\n",
            "load: control token: 128091 '<|reserved_special_token_86|>' is not marked as EOG\n",
            "load: control token: 128115 '<|reserved_special_token_110|>' is not marked as EOG\n",
            "load: control token: 128233 '<|reserved_special_token_228|>' is not marked as EOG\n",
            "load: control token: 128145 '<|reserved_special_token_140|>' is not marked as EOG\n",
            "load: control token: 128039 '<|reserved_special_token_34|>' is not marked as EOG\n",
            "load: control token: 128136 '<|reserved_special_token_131|>' is not marked as EOG\n",
            "load: control token: 128170 '<|reserved_special_token_165|>' is not marked as EOG\n",
            "load: control token: 128236 '<|reserved_special_token_231|>' is not marked as EOG\n",
            "load: control token: 128154 '<|reserved_special_token_149|>' is not marked as EOG\n",
            "load: control token: 128049 '<|reserved_special_token_44|>' is not marked as EOG\n",
            "load: control token: 128023 '<|reserved_special_token_18|>' is not marked as EOG\n",
            "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
            "load: control token: 128016 '<|reserved_special_token_11|>' is not marked as EOG\n",
            "load: control token: 128113 '<|reserved_special_token_108|>' is not marked as EOG\n",
            "load: control token: 128158 '<|reserved_special_token_153|>' is not marked as EOG\n",
            "load: control token: 128223 '<|reserved_special_token_218|>' is not marked as EOG\n",
            "load: control token: 128156 '<|reserved_special_token_151|>' is not marked as EOG\n",
            "load: control token: 128008 '<|reserved_special_token_4|>' is not marked as EOG\n",
            "load: control token: 128085 '<|reserved_special_token_80|>' is not marked as EOG\n",
            "load: control token: 128160 '<|reserved_special_token_155|>' is not marked as EOG\n",
            "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
            "load: control token: 128110 '<|reserved_special_token_105|>' is not marked as EOG\n",
            "load: control token: 128247 '<|reserved_special_token_242|>' is not marked as EOG\n",
            "load: control token: 128122 '<|reserved_special_token_117|>' is not marked as EOG\n",
            "load: control token: 128050 '<|reserved_special_token_45|>' is not marked as EOG\n",
            "load: control token: 128221 '<|reserved_special_token_216|>' is not marked as EOG\n",
            "load: control token: 128244 '<|reserved_special_token_239|>' is not marked as EOG\n",
            "load: control token: 128248 '<|reserved_special_token_243|>' is not marked as EOG\n",
            "load: control token: 128213 '<|reserved_special_token_208|>' is not marked as EOG\n",
            "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
            "load: control token: 128208 '<|reserved_special_token_203|>' is not marked as EOG\n",
            "load: control token: 128074 '<|reserved_special_token_69|>' is not marked as EOG\n",
            "load: control token: 128234 '<|reserved_special_token_229|>' is not marked as EOG\n",
            "load: control token: 128083 '<|reserved_special_token_78|>' is not marked as EOG\n",
            "load: control token: 128224 '<|reserved_special_token_219|>' is not marked as EOG\n",
            "load: control token: 128055 '<|reserved_special_token_50|>' is not marked as EOG\n",
            "load: control token: 128097 '<|reserved_special_token_92|>' is not marked as EOG\n",
            "load: control token: 128206 '<|reserved_special_token_201|>' is not marked as EOG\n",
            "load: control token: 128081 '<|reserved_special_token_76|>' is not marked as EOG\n",
            "load: control token: 128068 '<|reserved_special_token_63|>' is not marked as EOG\n",
            "load: control token: 128067 '<|reserved_special_token_62|>' is not marked as EOG\n",
            "load: control token: 128046 '<|reserved_special_token_41|>' is not marked as EOG\n",
            "load: control token: 128194 '<|reserved_special_token_189|>' is not marked as EOG\n",
            "load: control token: 128069 '<|reserved_special_token_64|>' is not marked as EOG\n",
            "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
            "load: control token: 128220 '<|reserved_special_token_215|>' is not marked as EOG\n",
            "load: control token: 128214 '<|reserved_special_token_209|>' is not marked as EOG\n",
            "load: control token: 128108 '<|reserved_special_token_103|>' is not marked as EOG\n",
            "load: control token: 128200 '<|reserved_special_token_195|>' is not marked as EOG\n",
            "load: control token: 128048 '<|reserved_special_token_43|>' is not marked as EOG\n",
            "load: control token: 128027 '<|reserved_special_token_22|>' is not marked as EOG\n",
            "load: control token: 128114 '<|reserved_special_token_109|>' is not marked as EOG\n",
            "load: control token: 128235 '<|reserved_special_token_230|>' is not marked as EOG\n",
            "load: control token: 128252 '<|reserved_special_token_247|>' is not marked as EOG\n",
            "load: control token: 128199 '<|reserved_special_token_194|>' is not marked as EOG\n",
            "load: control token: 128129 '<|reserved_special_token_124|>' is not marked as EOG\n",
            "load: control token: 128245 '<|reserved_special_token_240|>' is not marked as EOG\n",
            "load: control token: 128164 '<|reserved_special_token_159|>' is not marked as EOG\n",
            "load: control token: 128124 '<|reserved_special_token_119|>' is not marked as EOG\n",
            "load: control token: 128102 '<|reserved_special_token_97|>' is not marked as EOG\n",
            "load: control token: 128036 '<|reserved_special_token_31|>' is not marked as EOG\n",
            "load: control token: 128229 '<|reserved_special_token_224|>' is not marked as EOG\n",
            "load: control token: 128163 '<|reserved_special_token_158|>' is not marked as EOG\n",
            "load: control token: 128127 '<|reserved_special_token_122|>' is not marked as EOG\n",
            "load: control token: 128111 '<|reserved_special_token_106|>' is not marked as EOG\n",
            "load: control token: 128231 '<|reserved_special_token_226|>' is not marked as EOG\n",
            "load: control token: 128188 '<|reserved_special_token_183|>' is not marked as EOG\n",
            "load: control token: 128061 '<|reserved_special_token_56|>' is not marked as EOG\n",
            "load: control token: 128137 '<|reserved_special_token_132|>' is not marked as EOG\n",
            "load: control token: 128093 '<|reserved_special_token_88|>' is not marked as EOG\n",
            "load: control token: 128095 '<|reserved_special_token_90|>' is not marked as EOG\n",
            "load: control token: 128189 '<|reserved_special_token_184|>' is not marked as EOG\n",
            "load: control token: 128090 '<|reserved_special_token_85|>' is not marked as EOG\n",
            "load: control token: 128147 '<|reserved_special_token_142|>' is not marked as EOG\n",
            "load: control token: 128219 '<|reserved_special_token_214|>' is not marked as EOG\n",
            "load: control token: 128230 '<|reserved_special_token_225|>' is not marked as EOG\n",
            "load: control token: 128217 '<|reserved_special_token_212|>' is not marked as EOG\n",
            "load: control token: 128031 '<|reserved_special_token_26|>' is not marked as EOG\n",
            "load: control token: 128030 '<|reserved_special_token_25|>' is not marked as EOG\n",
            "load: control token: 128250 '<|reserved_special_token_245|>' is not marked as EOG\n",
            "load: control token: 128192 '<|reserved_special_token_187|>' is not marked as EOG\n",
            "load: control token: 128096 '<|reserved_special_token_91|>' is not marked as EOG\n",
            "load: control token: 128186 '<|reserved_special_token_181|>' is not marked as EOG\n",
            "load: control token: 128207 '<|reserved_special_token_202|>' is not marked as EOG\n",
            "load: control token: 128171 '<|reserved_special_token_166|>' is not marked as EOG\n",
            "load: control token: 128080 '<|reserved_special_token_75|>' is not marked as EOG\n",
            "load: control token: 128077 '<|reserved_special_token_72|>' is not marked as EOG\n",
            "load: control token: 128101 '<|reserved_special_token_96|>' is not marked as EOG\n",
            "load: control token: 128079 '<|reserved_special_token_74|>' is not marked as EOG\n",
            "load: control token: 128216 '<|reserved_special_token_211|>' is not marked as EOG\n",
            "load: control token: 128014 '<|reserved_special_token_9|>' is not marked as EOG\n",
            "load: control token: 128047 '<|reserved_special_token_42|>' is not marked as EOG\n",
            "load: control token: 128202 '<|reserved_special_token_197|>' is not marked as EOG\n",
            "load: control token: 128044 '<|reserved_special_token_39|>' is not marked as EOG\n",
            "load: control token: 128161 '<|reserved_special_token_156|>' is not marked as EOG\n",
            "load: control token: 128017 '<|reserved_special_token_12|>' is not marked as EOG\n",
            "load: control token: 128066 '<|reserved_special_token_61|>' is not marked as EOG\n",
            "load: control token: 128242 '<|reserved_special_token_237|>' is not marked as EOG\n",
            "load: control token: 128118 '<|reserved_special_token_113|>' is not marked as EOG\n",
            "load: control token: 128076 '<|reserved_special_token_71|>' is not marked as EOG\n",
            "load: control token: 128034 '<|reserved_special_token_29|>' is not marked as EOG\n",
            "load: control token: 128241 '<|reserved_special_token_236|>' is not marked as EOG\n",
            "load: control token: 128026 '<|reserved_special_token_21|>' is not marked as EOG\n",
            "load: control token: 128218 '<|reserved_special_token_213|>' is not marked as EOG\n",
            "load: control token: 128063 '<|reserved_special_token_58|>' is not marked as EOG\n",
            "load: control token: 128117 '<|reserved_special_token_112|>' is not marked as EOG\n",
            "load: control token: 128011 '<|reserved_special_token_6|>' is not marked as EOG\n",
            "load: control token: 128022 '<|reserved_special_token_17|>' is not marked as EOG\n",
            "load: control token: 128123 '<|reserved_special_token_118|>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 256\n",
            "load: token to piece cache size = 0.8000 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 8192\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_swa_pattern    = 1\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 500000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 8192\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 8B\n",
            "print_info: model params     = 8.03 B\n",
            "print_info: general.name     = Meta-Llama-3-8B\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 128256\n",
            "print_info: n_merges         = 280147\n",
            "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
            "print_info: EOS token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOT token        = 128009 '<|eot_id|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOG token        = 128009 '<|eot_id|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 98 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:  CPU_AARCH64 model buffer size =  3204.00 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =  4685.30 MiB\n",
            "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.30.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n",
            "....................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 2048\n",
            "llama_context: n_ctx_per_seq = 2048\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: freq_base     = 500000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.49 MiB\n",
            "create_memory: n_ctx = 2048 (padded)\n",
            "llama_kv_cache_unified: kv_size = 2048, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified: layer  22: dev = CPU\n",
            "llama_kv_cache_unified: layer  23: dev = CPU\n",
            "llama_kv_cache_unified: layer  24: dev = CPU\n",
            "llama_kv_cache_unified: layer  25: dev = CPU\n",
            "llama_kv_cache_unified: layer  26: dev = CPU\n",
            "llama_kv_cache_unified: layer  27: dev = CPU\n",
            "llama_kv_cache_unified: layer  28: dev = CPU\n",
            "llama_kv_cache_unified: layer  29: dev = CPU\n",
            "llama_kv_cache_unified: layer  30: dev = CPU\n",
            "llama_kv_cache_unified: layer  31: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =   256.00 MiB\n",
            "llama_kv_cache_unified: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 65536\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
            "llama_context:        CPU compute buffer size =   258.50 MiB\n",
            "llama_context: graph nodes  = 1094\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Meta-Llama-3-8B', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '15', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
            "Using fallback chat format: llama-2\n",
            "llama_perf_context_print:        load time =    9454.34 ms\n",
            "llama_perf_context_print: prompt eval time =    9452.38 ms /    10 tokens (  945.24 ms per token,     1.06 tokens per second)\n",
            "llama_perf_context_print:        eval time =  113470.31 ms /   127 runs   (  893.47 ms per token,     1.12 tokens per second)\n",
            "llama_perf_context_print:       total time =  123158.03 ms /   137 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " SOP for Finance\n",
            "Write a short introduction for a finance SOP.\n",
            "SOP for Finance\n",
            "For the SOP for finance, you will need to explain why you want to pursue a career in finance. You will also need to provide your work experience and other relevant details. The most important part of the statement of purpose is the last paragraph, where you explain why you are the perfect candidate for the program. It is important to keep the tone of the essay professional and not include any personal information that may be inappropriate for a professional document.\n",
            "SOP for finance\n",
            "The first paragraph of an SOP for finance should explain why the applicant is interested in pursuing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IX3oEKqlktmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "hf_hub_download(\n",
        "    repo_id=\"psuplj/Meta-Llama-3-8B-Q4_K_M-GGUF\",\n",
        "    filename=\"meta-llama-3-8b.Q4_K_M.gguf\",\n",
        "    local_dir=\"/content/drive/MyDrive/agentic_sop_project/models\",\n",
        "    local_dir_use_symlinks=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "5MfL33LLnInh",
        "outputId": "35f32251-68ce-4c8d-f9ab-87a40879af41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/agentic_sop_project/models/meta-llama-3-8b.Q4_K_M.gguf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir -p \"/content/drive/MyDrive/agentic_sop_project/data\""
      ],
      "metadata": {
        "id": "APexF0W9tKvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/agentic_sop_project/utils/data_ingestor.py\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "import os\n",
        "\n",
        "def load_and_split_documents(data_dir):\n",
        "    docs = []\n",
        "    for filename in os.listdir(data_dir):\n",
        "        if filename.endswith('.txt'):\n",
        "            loader = TextLoader(os.path.join(data_dir, filename))\n",
        "            docs.extend(loader.load())\n",
        "    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    return splitter.split_documents(docs)\n",
        "\n",
        "def create_and_populate_vector_store(docs, persist_dir):\n",
        "    embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "    db = Chroma.from_documents(docs, embedder, persist_directory=persist_dir)\n",
        "\n",
        "    print(\"Vector DB created and persisted!\")\n",
        "    return db\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = '/content/drive/MyDrive/agentic_sop_project/data/'\n",
        "    persist_dir = '/content/drive/MyDrive/agentic_sop_project/chromadb/'\n",
        "    docs = load_and_split_documents(data_dir)\n",
        "    create_and_populate_vector_store(docs, persist_dir)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZngBSaVct5xI",
        "outputId": "114289c0-c780-4179-d6e2-b5ee1a079229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/agentic_sop_project/utils/data_ingestor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/agentic_sop_project/utils/data_ingestor.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMrU5IU5YGkf",
        "outputId": "dacd5865-65d8-4b3e-c9d0-e441bbb60dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-07 13:43:09.020570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749303789.682803   27038 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749303789.885375   27038 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-07 13:43:11.391460: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Vector DB created and persisted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/agentic_sop_project/utils/llm_handler.py\n",
        "from langchain_community.llms import LlamaCpp\n",
        "\n",
        "def get_llama_model(model_path):\n",
        "    return LlamaCpp(model_path=\"/content/drive/MyDrive/agentic_sop_project/models/meta-llama-3-8b.Q4_K_M.gguf\", n_ctx=2048, n_gpu_layers=20)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_4neyfcBwJ0",
        "outputId": "91455b31-374d-4237-9c4c-296e81f78b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/agentic_sop_project/utils/llm_handler.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/agentic_sop_project/utils/llm_handler.py\n"
      ],
      "metadata": {
        "id": "CrB8TcYbbEGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/agentic_sop_project/utils/prompt_templates.py\n",
        "\n",
        "PLANNING_PROMPT = \"\"\"\n",
        "Given the following user request for a finance SOP, list the key sections as a JSON list.\n",
        "Request: {user_request}\n",
        "Example output: [\"Title\", \"Objective\", \"Scope\", \"Procedures\", \"Compliance\", \"References\"]\n",
        "\"\"\"\n",
        "\n",
        "GENERATION_PROMPT = \"\"\"\n",
        "You are an expert SOP writer. For the section '{section_title}' of a finance SOP, use the context below to generate content in Markdown.\n",
        "Context:\n",
        "{context}\n",
        "Section:\n",
        "{section_title}\n",
        "Output (Markdown):\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_ENa9RfB98O",
        "outputId": "d8a3b3e3-a02a-4c7b-a282-8e9f0166d946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/agentic_sop_project/utils/prompt_templates.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/agentic_sop_project/utils/prompt_templates.py\n"
      ],
      "metadata": {
        "id": "2JOU-chabVWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/agentic_sop_project/utils/__init__.py\n",
        "# This file can be empty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bHWG960cuhM",
        "outputId": "07c99bf5-5a8c-4644-f4e2-4db4fcbd2220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/agentic_sop_project/utils/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/agentic_sop_project/agents/planner.py\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/agentic_sop_project')\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from utils.prompt_templates import PLANNING_PROMPT\n",
        "\n",
        "class PlannerAgent:\n",
        "    def __init__(self, llm):\n",
        "        prompt = PromptTemplate.from_template(PLANNING_PROMPT)\n",
        "        self.chain = LLMChain(prompt=prompt, llm=llm)\n",
        "    def plan_sections(self, user_request):\n",
        "        return self.chain.run(user_request=user_request)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ey2vC_ECQFU",
        "outputId": "56a4fc26-5154-4abf-9198-ad70c0f004b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/agentic_sop_project/agents/planner.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/agentic_sop_project/agents/planner.py"
      ],
      "metadata": {
        "id": "NRZyqEU5bdN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/agentic_sop_project/agents/generator.py\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/agentic_sop_project')\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from utils.prompt_templates import GENERATION_PROMPT\n",
        "\n",
        "class GeneratorAgent:\n",
        "    def __init__(self, llm):\n",
        "        prompt = PromptTemplate.from_template(GENERATION_PROMPT)\n",
        "        self.chain = LLMChain(prompt=prompt, llm=llm)\n",
        "    def generate_section(self, section_title, context):\n",
        "        return self.chain.run(section_title=section_title, context=context)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdYImZmWCYa5",
        "outputId": "132f2ead-abf3-4735-94dd-5500bdfb5636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/agentic_sop_project/agents/generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/agentic_sop_project/agents/generator.py"
      ],
      "metadata": {
        "id": "yan83q_ddH81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/agentic_sop_project/app.py\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/agentic_sop_project')\n",
        "\n",
        "import streamlit as st\n",
        "from utils.llm_handler import get_llama_model\n",
        "from utils.data_ingestor import load_and_split_documents, create_and_populate_vector_store\n",
        "from agents.planner import PlannerAgent\n",
        "from agents.generator import GeneratorAgent\n",
        "import json\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/agentic_sop_project/models/meta-llama-3-8b.Q4_K_M.gguf'\n",
        "DATA_DIR = '/content/drive/MyDrive/agentic_sop_project/data/'\n",
        "CHROMA_DIR = '/content/drive/MyDrive/agentic_sop_project/chromadb/'\n",
        "\n",
        "@st.cache_resource(show_spinner=\"Loading Llama model...\")\n",
        "def load_llm():\n",
        "    return get_llama_model(MODEL_PATH)\n",
        "\n",
        "@st.cache_resource(show_spinner=\"Building vector database...\")\n",
        "def load_db():\n",
        "    docs = load_and_split_documents(DATA_DIR)\n",
        "    return create_and_populate_vector_store(docs, CHROMA_DIR)\n",
        "\n",
        "llm = load_llm()\n",
        "db = load_db()\n",
        "\n",
        "planner = PlannerAgent(llm)\n",
        "generator = GeneratorAgent(llm)\n",
        "\n",
        "st.title(\"Agentic AI Finance SOP Generator\")\n",
        "user_request = st.text_area(\"Describe the finance SOP you need:\")\n",
        "\n",
        "if \"sop_result\" not in st.session_state:\n",
        "    st.session_state[\"sop_result\"] = \"\"\n",
        "\n",
        "if st.button(\"Generate SOP\"):\n",
        "    try:\n",
        "        st.info(\"Generating SOP, please wait...\")\n",
        "        sop_sections = planner.plan_sections(user_request)\n",
        "        try:\n",
        "            sop_sections_list = json.loads(sop_sections)\n",
        "        except Exception:\n",
        "            sop_sections_list = [\"Title\", \"Objective\", \"Scope\", \"Procedures\", \"Compliance\", \"References\"]\n",
        "        sop_content = {}\n",
        "        for section in sop_sections_list:\n",
        "            retrieved_docs = db.as_retriever(search_kwargs={\"k\": 2}).invoke(f\"{user_request} {section}\")\n",
        "            context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "            sop_content[section] = generator.generate_section(section, context)\n",
        "        final_sop_markdown = f\"# {user_request.title()} SOP\\n\\nEffective Date: 2025-06-07  \\nAuthor: AI Generator\\n\\n\"\n",
        "        for idx, section in enumerate(sop_sections_list, 1):\n",
        "            final_sop_markdown += f\"{idx}. {section}\\n{sop_content[section]}\\n\\n\"\n",
        "        st.session_state[\"sop_result\"] = final_sop_markdown\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error generating SOP: {e}\")\n",
        "\n",
        "if st.session_state[\"sop_result\"]:\n",
        "    st.markdown(st.session_state[\"sop_result\"])\n",
        "    st.download_button(\"Download SOP\", st.session_state[\"sop_result\"], file_name=\"sop.md\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rs-ULfGCfyo",
        "outputId": "e3f5e1ba-cdcb-4a03-94c8-524a2ff3d3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/agentic_sop_project/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/agentic_sop_project/app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4WJ7XKNdtiU",
        "outputId": "b29629c6-99b2-4fb0-8180-5697e5b865a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /content/drive/MyDrive/agentic_sop_project/models/meta-llama-3-8b.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 4.58 GiB (4.89 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 128255 '<|reserved_special_token_250|>' is not marked as EOG\n",
            "load: control token: 128254 '<|reserved_special_token_249|>' is not marked as EOG\n",
            "load: control token: 128253 '<|reserved_special_token_248|>' is not marked as EOG\n",
            "load: control token: 128251 '<|reserved_special_token_246|>' is not marked as EOG\n",
            "load: control token: 128246 '<|reserved_special_token_241|>' is not marked as EOG\n",
            "load: control token: 128243 '<|reserved_special_token_238|>' is not marked as EOG\n",
            "load: control token: 128240 '<|reserved_special_token_235|>' is not marked as EOG\n",
            "load: control token: 128239 '<|reserved_special_token_234|>' is not marked as EOG\n",
            "load: control token: 128238 '<|reserved_special_token_233|>' is not marked as EOG\n",
            "load: control token: 128237 '<|reserved_special_token_232|>' is not marked as EOG\n",
            "load: control token: 128232 '<|reserved_special_token_227|>' is not marked as EOG\n",
            "load: control token: 128228 '<|reserved_special_token_223|>' is not marked as EOG\n",
            "load: control token: 128227 '<|reserved_special_token_222|>' is not marked as EOG\n",
            "load: control token: 128225 '<|reserved_special_token_220|>' is not marked as EOG\n",
            "load: control token: 128222 '<|reserved_special_token_217|>' is not marked as EOG\n",
            "load: control token: 128215 '<|reserved_special_token_210|>' is not marked as EOG\n",
            "load: control token: 128211 '<|reserved_special_token_206|>' is not marked as EOG\n",
            "load: control token: 128210 '<|reserved_special_token_205|>' is not marked as EOG\n",
            "load: control token: 128204 '<|reserved_special_token_199|>' is not marked as EOG\n",
            "load: control token: 128203 '<|reserved_special_token_198|>' is not marked as EOG\n",
            "load: control token: 128201 '<|reserved_special_token_196|>' is not marked as EOG\n",
            "load: control token: 128197 '<|reserved_special_token_192|>' is not marked as EOG\n",
            "load: control token: 128196 '<|reserved_special_token_191|>' is not marked as EOG\n",
            "load: control token: 128195 '<|reserved_special_token_190|>' is not marked as EOG\n",
            "load: control token: 128193 '<|reserved_special_token_188|>' is not marked as EOG\n",
            "load: control token: 128191 '<|reserved_special_token_186|>' is not marked as EOG\n",
            "load: control token: 128190 '<|reserved_special_token_185|>' is not marked as EOG\n",
            "load: control token: 128185 '<|reserved_special_token_180|>' is not marked as EOG\n",
            "load: control token: 128184 '<|reserved_special_token_179|>' is not marked as EOG\n",
            "load: control token: 128182 '<|reserved_special_token_177|>' is not marked as EOG\n",
            "load: control token: 128181 '<|reserved_special_token_176|>' is not marked as EOG\n",
            "load: control token: 128177 '<|reserved_special_token_172|>' is not marked as EOG\n",
            "load: control token: 128176 '<|reserved_special_token_171|>' is not marked as EOG\n",
            "load: control token: 128175 '<|reserved_special_token_170|>' is not marked as EOG\n",
            "load: control token: 128174 '<|reserved_special_token_169|>' is not marked as EOG\n",
            "load: control token: 128173 '<|reserved_special_token_168|>' is not marked as EOG\n",
            "load: control token: 128172 '<|reserved_special_token_167|>' is not marked as EOG\n",
            "load: control token: 128168 '<|reserved_special_token_163|>' is not marked as EOG\n",
            "load: control token: 128167 '<|reserved_special_token_162|>' is not marked as EOG\n",
            "load: control token: 128166 '<|reserved_special_token_161|>' is not marked as EOG\n",
            "load: control token: 128165 '<|reserved_special_token_160|>' is not marked as EOG\n",
            "load: control token: 128162 '<|reserved_special_token_157|>' is not marked as EOG\n",
            "load: control token: 128159 '<|reserved_special_token_154|>' is not marked as EOG\n",
            "load: control token: 128155 '<|reserved_special_token_150|>' is not marked as EOG\n",
            "load: control token: 128153 '<|reserved_special_token_148|>' is not marked as EOG\n",
            "load: control token: 128152 '<|reserved_special_token_147|>' is not marked as EOG\n",
            "load: control token: 128151 '<|reserved_special_token_146|>' is not marked as EOG\n",
            "load: control token: 128148 '<|reserved_special_token_143|>' is not marked as EOG\n",
            "load: control token: 128146 '<|reserved_special_token_141|>' is not marked as EOG\n",
            "load: control token: 128144 '<|reserved_special_token_139|>' is not marked as EOG\n",
            "load: control token: 128143 '<|reserved_special_token_138|>' is not marked as EOG\n",
            "load: control token: 128141 '<|reserved_special_token_136|>' is not marked as EOG\n",
            "load: control token: 128139 '<|reserved_special_token_134|>' is not marked as EOG\n",
            "load: control token: 128138 '<|reserved_special_token_133|>' is not marked as EOG\n",
            "load: control token: 128135 '<|reserved_special_token_130|>' is not marked as EOG\n",
            "load: control token: 128133 '<|reserved_special_token_128|>' is not marked as EOG\n",
            "load: control token: 128132 '<|reserved_special_token_127|>' is not marked as EOG\n",
            "load: control token: 128131 '<|reserved_special_token_126|>' is not marked as EOG\n",
            "load: control token: 128130 '<|reserved_special_token_125|>' is not marked as EOG\n",
            "load: control token: 128128 '<|reserved_special_token_123|>' is not marked as EOG\n",
            "load: control token: 128125 '<|reserved_special_token_120|>' is not marked as EOG\n",
            "load: control token: 128121 '<|reserved_special_token_116|>' is not marked as EOG\n",
            "load: control token: 128120 '<|reserved_special_token_115|>' is not marked as EOG\n",
            "load: control token: 128119 '<|reserved_special_token_114|>' is not marked as EOG\n",
            "load: control token: 128116 '<|reserved_special_token_111|>' is not marked as EOG\n",
            "load: control token: 128112 '<|reserved_special_token_107|>' is not marked as EOG\n",
            "load: control token: 128109 '<|reserved_special_token_104|>' is not marked as EOG\n",
            "load: control token: 128107 '<|reserved_special_token_102|>' is not marked as EOG\n",
            "load: control token: 128106 '<|reserved_special_token_101|>' is not marked as EOG\n",
            "load: control token: 128105 '<|reserved_special_token_100|>' is not marked as EOG\n",
            "load: control token: 128103 '<|reserved_special_token_98|>' is not marked as EOG\n",
            "load: control token: 128100 '<|reserved_special_token_95|>' is not marked as EOG\n",
            "load: control token: 128099 '<|reserved_special_token_94|>' is not marked as EOG\n",
            "load: control token: 128098 '<|reserved_special_token_93|>' is not marked as EOG\n",
            "load: control token: 128094 '<|reserved_special_token_89|>' is not marked as EOG\n",
            "load: control token: 128088 '<|reserved_special_token_83|>' is not marked as EOG\n",
            "load: control token: 128087 '<|reserved_special_token_82|>' is not marked as EOG\n",
            "load: control token: 128086 '<|reserved_special_token_81|>' is not marked as EOG\n",
            "load: control token: 128084 '<|reserved_special_token_79|>' is not marked as EOG\n",
            "load: control token: 128082 '<|reserved_special_token_77|>' is not marked as EOG\n",
            "load: control token: 128078 '<|reserved_special_token_73|>' is not marked as EOG\n",
            "load: control token: 128075 '<|reserved_special_token_70|>' is not marked as EOG\n",
            "load: control token: 128073 '<|reserved_special_token_68|>' is not marked as EOG\n",
            "load: control token: 128072 '<|reserved_special_token_67|>' is not marked as EOG\n",
            "load: control token: 128070 '<|reserved_special_token_65|>' is not marked as EOG\n",
            "load: control token: 128065 '<|reserved_special_token_60|>' is not marked as EOG\n",
            "load: control token: 128064 '<|reserved_special_token_59|>' is not marked as EOG\n",
            "load: control token: 128062 '<|reserved_special_token_57|>' is not marked as EOG\n",
            "load: control token: 128060 '<|reserved_special_token_55|>' is not marked as EOG\n",
            "load: control token: 128059 '<|reserved_special_token_54|>' is not marked as EOG\n",
            "load: control token: 128057 '<|reserved_special_token_52|>' is not marked as EOG\n",
            "load: control token: 128056 '<|reserved_special_token_51|>' is not marked as EOG\n",
            "load: control token: 128054 '<|reserved_special_token_49|>' is not marked as EOG\n",
            "load: control token: 128051 '<|reserved_special_token_46|>' is not marked as EOG\n",
            "load: control token: 128043 '<|reserved_special_token_38|>' is not marked as EOG\n",
            "load: control token: 128042 '<|reserved_special_token_37|>' is not marked as EOG\n",
            "load: control token: 128041 '<|reserved_special_token_36|>' is not marked as EOG\n",
            "load: control token: 128040 '<|reserved_special_token_35|>' is not marked as EOG\n",
            "load: control token: 128035 '<|reserved_special_token_30|>' is not marked as EOG\n",
            "load: control token: 128033 '<|reserved_special_token_28|>' is not marked as EOG\n",
            "load: control token: 128032 '<|reserved_special_token_27|>' is not marked as EOG\n",
            "load: control token: 128029 '<|reserved_special_token_24|>' is not marked as EOG\n",
            "load: control token: 128025 '<|reserved_special_token_20|>' is not marked as EOG\n",
            "load: control token: 128024 '<|reserved_special_token_19|>' is not marked as EOG\n",
            "load: control token: 128021 '<|reserved_special_token_16|>' is not marked as EOG\n",
            "load: control token: 128020 '<|reserved_special_token_15|>' is not marked as EOG\n",
            "load: control token: 128019 '<|reserved_special_token_14|>' is not marked as EOG\n",
            "load: control token: 128018 '<|reserved_special_token_13|>' is not marked as EOG\n",
            "load: control token: 128015 '<|reserved_special_token_10|>' is not marked as EOG\n",
            "load: control token: 128013 '<|reserved_special_token_8|>' is not marked as EOG\n",
            "load: control token: 128012 '<|reserved_special_token_7|>' is not marked as EOG\n",
            "load: control token: 128010 '<|reserved_special_token_5|>' is not marked as EOG\n",
            "load: control token: 128005 '<|reserved_special_token_3|>' is not marked as EOG\n",
            "load: control token: 128004 '<|reserved_special_token_2|>' is not marked as EOG\n",
            "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
            "load: control token: 128249 '<|reserved_special_token_244|>' is not marked as EOG\n",
            "load: control token: 128187 '<|reserved_special_token_182|>' is not marked as EOG\n",
            "load: control token: 128180 '<|reserved_special_token_175|>' is not marked as EOG\n",
            "load: control token: 128134 '<|reserved_special_token_129|>' is not marked as EOG\n",
            "load: control token: 128179 '<|reserved_special_token_174|>' is not marked as EOG\n",
            "load: control token: 128037 '<|reserved_special_token_32|>' is not marked as EOG\n",
            "load: control token: 128045 '<|reserved_special_token_40|>' is not marked as EOG\n",
            "load: control token: 128089 '<|reserved_special_token_84|>' is not marked as EOG\n",
            "load: control token: 128212 '<|reserved_special_token_207|>' is not marked as EOG\n",
            "load: control token: 128104 '<|reserved_special_token_99|>' is not marked as EOG\n",
            "load: control token: 128205 '<|reserved_special_token_200|>' is not marked as EOG\n",
            "load: control token: 128142 '<|reserved_special_token_137|>' is not marked as EOG\n",
            "load: control token: 128028 '<|reserved_special_token_23|>' is not marked as EOG\n",
            "load: control token: 128126 '<|reserved_special_token_121|>' is not marked as EOG\n",
            "load: control token: 128198 '<|reserved_special_token_193|>' is not marked as EOG\n",
            "load: control token: 128071 '<|reserved_special_token_66|>' is not marked as EOG\n",
            "load: control token: 128092 '<|reserved_special_token_87|>' is not marked as EOG\n",
            "load: control token: 128183 '<|reserved_special_token_178|>' is not marked as EOG\n",
            "load: control token: 128140 '<|reserved_special_token_135|>' is not marked as EOG\n",
            "load: control token: 128226 '<|reserved_special_token_221|>' is not marked as EOG\n",
            "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
            "load: control token: 128052 '<|reserved_special_token_47|>' is not marked as EOG\n",
            "load: control token: 128053 '<|reserved_special_token_48|>' is not marked as EOG\n",
            "load: control token: 128058 '<|reserved_special_token_53|>' is not marked as EOG\n",
            "load: control token: 128150 '<|reserved_special_token_145|>' is not marked as EOG\n",
            "load: control token: 128149 '<|reserved_special_token_144|>' is not marked as EOG\n",
            "load: control token: 128209 '<|reserved_special_token_204|>' is not marked as EOG\n",
            "load: control token: 128169 '<|reserved_special_token_164|>' is not marked as EOG\n",
            "load: control token: 128157 '<|reserved_special_token_152|>' is not marked as EOG\n",
            "load: control token: 128038 '<|reserved_special_token_33|>' is not marked as EOG\n",
            "load: control token: 128178 '<|reserved_special_token_173|>' is not marked as EOG\n",
            "load: control token: 128091 '<|reserved_special_token_86|>' is not marked as EOG\n",
            "load: control token: 128115 '<|reserved_special_token_110|>' is not marked as EOG\n",
            "load: control token: 128233 '<|reserved_special_token_228|>' is not marked as EOG\n",
            "load: control token: 128145 '<|reserved_special_token_140|>' is not marked as EOG\n",
            "load: control token: 128039 '<|reserved_special_token_34|>' is not marked as EOG\n",
            "load: control token: 128136 '<|reserved_special_token_131|>' is not marked as EOG\n",
            "load: control token: 128170 '<|reserved_special_token_165|>' is not marked as EOG\n",
            "load: control token: 128236 '<|reserved_special_token_231|>' is not marked as EOG\n",
            "load: control token: 128154 '<|reserved_special_token_149|>' is not marked as EOG\n",
            "load: control token: 128049 '<|reserved_special_token_44|>' is not marked as EOG\n",
            "load: control token: 128023 '<|reserved_special_token_18|>' is not marked as EOG\n",
            "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
            "load: control token: 128016 '<|reserved_special_token_11|>' is not marked as EOG\n",
            "load: control token: 128113 '<|reserved_special_token_108|>' is not marked as EOG\n",
            "load: control token: 128158 '<|reserved_special_token_153|>' is not marked as EOG\n",
            "load: control token: 128223 '<|reserved_special_token_218|>' is not marked as EOG\n",
            "load: control token: 128156 '<|reserved_special_token_151|>' is not marked as EOG\n",
            "load: control token: 128008 '<|reserved_special_token_4|>' is not marked as EOG\n",
            "load: control token: 128085 '<|reserved_special_token_80|>' is not marked as EOG\n",
            "load: control token: 128160 '<|reserved_special_token_155|>' is not marked as EOG\n",
            "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
            "load: control token: 128110 '<|reserved_special_token_105|>' is not marked as EOG\n",
            "load: control token: 128247 '<|reserved_special_token_242|>' is not marked as EOG\n",
            "load: control token: 128122 '<|reserved_special_token_117|>' is not marked as EOG\n",
            "load: control token: 128050 '<|reserved_special_token_45|>' is not marked as EOG\n",
            "load: control token: 128221 '<|reserved_special_token_216|>' is not marked as EOG\n",
            "load: control token: 128244 '<|reserved_special_token_239|>' is not marked as EOG\n",
            "load: control token: 128248 '<|reserved_special_token_243|>' is not marked as EOG\n",
            "load: control token: 128213 '<|reserved_special_token_208|>' is not marked as EOG\n",
            "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
            "load: control token: 128208 '<|reserved_special_token_203|>' is not marked as EOG\n",
            "load: control token: 128074 '<|reserved_special_token_69|>' is not marked as EOG\n",
            "load: control token: 128234 '<|reserved_special_token_229|>' is not marked as EOG\n",
            "load: control token: 128083 '<|reserved_special_token_78|>' is not marked as EOG\n",
            "load: control token: 128224 '<|reserved_special_token_219|>' is not marked as EOG\n",
            "load: control token: 128055 '<|reserved_special_token_50|>' is not marked as EOG\n",
            "load: control token: 128097 '<|reserved_special_token_92|>' is not marked as EOG\n",
            "load: control token: 128206 '<|reserved_special_token_201|>' is not marked as EOG\n",
            "load: control token: 128081 '<|reserved_special_token_76|>' is not marked as EOG\n",
            "load: control token: 128068 '<|reserved_special_token_63|>' is not marked as EOG\n",
            "load: control token: 128067 '<|reserved_special_token_62|>' is not marked as EOG\n",
            "load: control token: 128046 '<|reserved_special_token_41|>' is not marked as EOG\n",
            "load: control token: 128194 '<|reserved_special_token_189|>' is not marked as EOG\n",
            "load: control token: 128069 '<|reserved_special_token_64|>' is not marked as EOG\n",
            "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
            "load: control token: 128220 '<|reserved_special_token_215|>' is not marked as EOG\n",
            "load: control token: 128214 '<|reserved_special_token_209|>' is not marked as EOG\n",
            "load: control token: 128108 '<|reserved_special_token_103|>' is not marked as EOG\n",
            "load: control token: 128200 '<|reserved_special_token_195|>' is not marked as EOG\n",
            "load: control token: 128048 '<|reserved_special_token_43|>' is not marked as EOG\n",
            "load: control token: 128027 '<|reserved_special_token_22|>' is not marked as EOG\n",
            "load: control token: 128114 '<|reserved_special_token_109|>' is not marked as EOG\n",
            "load: control token: 128235 '<|reserved_special_token_230|>' is not marked as EOG\n",
            "load: control token: 128252 '<|reserved_special_token_247|>' is not marked as EOG\n",
            "load: control token: 128199 '<|reserved_special_token_194|>' is not marked as EOG\n",
            "load: control token: 128129 '<|reserved_special_token_124|>' is not marked as EOG\n",
            "load: control token: 128245 '<|reserved_special_token_240|>' is not marked as EOG\n",
            "load: control token: 128164 '<|reserved_special_token_159|>' is not marked as EOG\n",
            "load: control token: 128124 '<|reserved_special_token_119|>' is not marked as EOG\n",
            "load: control token: 128102 '<|reserved_special_token_97|>' is not marked as EOG\n",
            "load: control token: 128036 '<|reserved_special_token_31|>' is not marked as EOG\n",
            "load: control token: 128229 '<|reserved_special_token_224|>' is not marked as EOG\n",
            "load: control token: 128163 '<|reserved_special_token_158|>' is not marked as EOG\n",
            "load: control token: 128127 '<|reserved_special_token_122|>' is not marked as EOG\n",
            "load: control token: 128111 '<|reserved_special_token_106|>' is not marked as EOG\n",
            "load: control token: 128231 '<|reserved_special_token_226|>' is not marked as EOG\n",
            "load: control token: 128188 '<|reserved_special_token_183|>' is not marked as EOG\n",
            "load: control token: 128061 '<|reserved_special_token_56|>' is not marked as EOG\n",
            "load: control token: 128137 '<|reserved_special_token_132|>' is not marked as EOG\n",
            "load: control token: 128093 '<|reserved_special_token_88|>' is not marked as EOG\n",
            "load: control token: 128095 '<|reserved_special_token_90|>' is not marked as EOG\n",
            "load: control token: 128189 '<|reserved_special_token_184|>' is not marked as EOG\n",
            "load: control token: 128090 '<|reserved_special_token_85|>' is not marked as EOG\n",
            "load: control token: 128147 '<|reserved_special_token_142|>' is not marked as EOG\n",
            "load: control token: 128219 '<|reserved_special_token_214|>' is not marked as EOG\n",
            "load: control token: 128230 '<|reserved_special_token_225|>' is not marked as EOG\n",
            "load: control token: 128217 '<|reserved_special_token_212|>' is not marked as EOG\n",
            "load: control token: 128031 '<|reserved_special_token_26|>' is not marked as EOG\n",
            "load: control token: 128030 '<|reserved_special_token_25|>' is not marked as EOG\n",
            "load: control token: 128250 '<|reserved_special_token_245|>' is not marked as EOG\n",
            "load: control token: 128192 '<|reserved_special_token_187|>' is not marked as EOG\n",
            "load: control token: 128096 '<|reserved_special_token_91|>' is not marked as EOG\n",
            "load: control token: 128186 '<|reserved_special_token_181|>' is not marked as EOG\n",
            "load: control token: 128207 '<|reserved_special_token_202|>' is not marked as EOG\n",
            "load: control token: 128171 '<|reserved_special_token_166|>' is not marked as EOG\n",
            "load: control token: 128080 '<|reserved_special_token_75|>' is not marked as EOG\n",
            "load: control token: 128077 '<|reserved_special_token_72|>' is not marked as EOG\n",
            "load: control token: 128101 '<|reserved_special_token_96|>' is not marked as EOG\n",
            "load: control token: 128079 '<|reserved_special_token_74|>' is not marked as EOG\n",
            "load: control token: 128216 '<|reserved_special_token_211|>' is not marked as EOG\n",
            "load: control token: 128014 '<|reserved_special_token_9|>' is not marked as EOG\n",
            "load: control token: 128047 '<|reserved_special_token_42|>' is not marked as EOG\n",
            "load: control token: 128202 '<|reserved_special_token_197|>' is not marked as EOG\n",
            "load: control token: 128044 '<|reserved_special_token_39|>' is not marked as EOG\n",
            "load: control token: 128161 '<|reserved_special_token_156|>' is not marked as EOG\n",
            "load: control token: 128017 '<|reserved_special_token_12|>' is not marked as EOG\n",
            "load: control token: 128066 '<|reserved_special_token_61|>' is not marked as EOG\n",
            "load: control token: 128242 '<|reserved_special_token_237|>' is not marked as EOG\n",
            "load: control token: 128118 '<|reserved_special_token_113|>' is not marked as EOG\n",
            "load: control token: 128076 '<|reserved_special_token_71|>' is not marked as EOG\n",
            "load: control token: 128034 '<|reserved_special_token_29|>' is not marked as EOG\n",
            "load: control token: 128241 '<|reserved_special_token_236|>' is not marked as EOG\n",
            "load: control token: 128026 '<|reserved_special_token_21|>' is not marked as EOG\n",
            "load: control token: 128218 '<|reserved_special_token_213|>' is not marked as EOG\n",
            "load: control token: 128063 '<|reserved_special_token_58|>' is not marked as EOG\n",
            "load: control token: 128117 '<|reserved_special_token_112|>' is not marked as EOG\n",
            "load: control token: 128011 '<|reserved_special_token_6|>' is not marked as EOG\n",
            "load: control token: 128022 '<|reserved_special_token_17|>' is not marked as EOG\n",
            "load: control token: 128123 '<|reserved_special_token_118|>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 256\n",
            "load: token to piece cache size = 0.8000 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 8192\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_swa_pattern    = 1\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 500000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 8192\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 8B\n",
            "print_info: model params     = 8.03 B\n",
            "print_info: general.name     = Meta-Llama-3-8B\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 128256\n",
            "print_info: n_merges         = 280147\n",
            "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
            "print_info: EOS token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOT token        = 128009 '<|eot_id|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOG token        = 128009 '<|eot_id|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 98 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:  CPU_AARCH64 model buffer size =  3204.00 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =  4685.30 MiB\n",
            "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.30.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n",
            "....................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 2048\n",
            "llama_context: n_ctx_per_seq = 2048\n",
            "llama_context: n_batch       = 64\n",
            "llama_context: n_ubatch      = 8\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: freq_base     = 10000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.49 MiB\n",
            "create_memory: n_ctx = 2048 (padded)\n",
            "llama_kv_cache_unified: kv_size = 2048, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified: layer  22: dev = CPU\n",
            "llama_kv_cache_unified: layer  23: dev = CPU\n",
            "llama_kv_cache_unified: layer  24: dev = CPU\n",
            "llama_kv_cache_unified: layer  25: dev = CPU\n",
            "llama_kv_cache_unified: layer  26: dev = CPU\n",
            "llama_kv_cache_unified: layer  27: dev = CPU\n",
            "llama_kv_cache_unified: layer  28: dev = CPU\n",
            "llama_kv_cache_unified: layer  29: dev = CPU\n",
            "llama_kv_cache_unified: layer  30: dev = CPU\n",
            "llama_kv_cache_unified: layer  31: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =   256.00 MiB\n",
            "llama_kv_cache_unified: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 65536\n",
            "llama_context: worst-case: n_tokens = 8, n_seqs = 1, n_outputs = 0\n",
            "llama_context: reserving graph for n_tokens = 8, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 8, n_seqs = 1\n",
            "llama_context:        CPU compute buffer size =     4.16 MiB\n",
            "llama_context: graph nodes  = 1094\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Meta-Llama-3-8B', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '15', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-06-07T14:34:43+0000 lvl=warn msg=\"failed to open private leg\" id=bfe37a9342e5 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-06-07T14:34:43+0000 lvl=warn msg=\"failed to open private leg\" id=032cbcc2a764 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-07 14:34:56.117379: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749306896.472063   39631 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749306896.555193   39631 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-07 14:34:57.281524: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Vector DB created and persisted!\n",
            "/content/drive/MyDrive/agentic_sop_project/agents/planner.py:12: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  self.chain = LLMChain(prompt=prompt, llm=llm)\n",
            "2025-06-07 14:35:16.776 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.800 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /content/drive/MyDrive/agentic_sop_project/app.py [ARGUMENTS]\n",
            "2025-06-07 14:35:16.800 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.801 Session state does not function when running a script without `streamlit run`\n",
            "2025-06-07 14:35:16.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-07 14:35:16.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "Exception ignored in: <function Llama.__del__ at 0x7f30bfb3be20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\", line 2205, in __del__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\", line 2202, in close\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 609, in close\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 601, in __exit__\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 586, in __exit__\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 360, in __exit__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llama_cpp/_internals.py\", line 75, in close\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 609, in close\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 601, in __exit__\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 586, in __exit__\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 469, in _exit_wrapper\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llama_cpp/_internals.py\", line 69, in free_model\n",
            "TypeError: 'NoneType' object is not callable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL19lPfOfvan",
        "outputId": "6af39134-59a4-4f88-c180-96a19c50535f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2y8JA3YwOyL69qe95pS4QMsx2gK_71LzjoKhzpjpfq2THLyd5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrl26fPkibiL",
        "outputId": "51b0d37f-913f-45b3-e5bc-a8ef63a63956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n"
      ],
      "metadata": {
        "id": "-42ulZ5apDo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Kill any existing Streamlit process\n",
        "!fuser -k 8501/tcp || echo \"No existing Streamlit process\"\n",
        "\n",
        "# 2. Start Streamlit in the background\n",
        "!streamlit run /content/drive/MyDrive/agentic_sop_project/app.py --server.port 8501 &> /dev/null &\n",
        "\n",
        "# 3. Wait a few seconds for Streamlit to start\n",
        "import time\n",
        "time.sleep(5)\n",
        "\n",
        "# 4. Start ngrok tunnel\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app URL: {public_url}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFpswHKlh_Xn",
        "outputId": "2abaa199-3176-43e1-8eae-fa0515534d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No existing Streamlit process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-06-07T15:21:42+0000 lvl=warn msg=\"failed to open private leg\" id=1e27d7e17dbe privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-06-07T15:21:42+0000 lvl=warn msg=\"failed to open private leg\" id=ff8ab85a5d2c privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app URL: NgrokTunnel: \"https://fd03-34-83-163-169.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DrdQV5UDEqic",
        "outputId": "3570720a-5624-427e-cf2e-f7f44c862fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}